# ğŸ” Der "Agent Loop" â€“ Hauptschleife des AI-Agenten - Siehe 4ï¸âƒ£ !!!
# Diese Schleife wird wiederholt ausgefÃ¼hrt, bis eine Abbruchbedingung erreicht ist.
# Sie simuliert, wie ein KI-Agent denkt, handelt und sein GedÃ¤chtnis aktualisiert.
# Der Agent erstellt zu diesem Zeitpunkt keine Funktionen, sondern koordiniert deren Verhalten. 
# Das bedeutet, dass die Logik fÃ¼r die Funktionsweise jedes Tools im Code vordefiniert ist und sich der Agent darauf konzentriert, das richtige Tool fÃ¼r die jeweilige Aufgabe auszuwÃ¤hlen und die richtigen Eingaben fÃ¼r dieses Tool bereitzustellen.

while iterations < max_iterations:

    # 1ï¸âƒ£ Prompt erstellen: Agenten-Regeln + bisheriges GedÃ¤chtnis kombinieren.
    # 'agent_rules' enthÃ¤lt die fixen Verhaltensregeln (z. B. "Du bist ein hilfreicher Assistent"),
    # 'memory' enthÃ¤lt den bisherigen GesprÃ¤chsverlauf oder Kontext.
    prompt = agent_rules + memory # Kombiniert die Regeln (assistent) und das GedÃ¤chtnis (response) zu einem Prompt fÃ¼r das LLM.

    # 2ï¸âƒ£ Antwort generieren / vom Sprachmodell (LLM) erzeugen
    print("Agent thinking...")  # Statusausgabe fÃ¼r den Benutzer
    response = generate_response(prompt)  # Anfrage an das LLM
    print(f"Agent response: {response}")  # Ausgabe der Antwort (z. B. welche Aktion es vorschlÃ¤gt)

    # 3ï¸âƒ£ Antwort analysieren, um herauszufinden, welche Aktion ausgefÃ¼hrt werden soll
    # 'parse_action' ist eine Hilfsfunktion, die den Text der LLM-Antwort
    # in eine strukturierte Aktion (Dictionary) umwandelt.
    action = parse_action(response)

    # Variable zum Speichern des Aktionsergebnisses
    result = "Action executed"

    # 4ï¸âƒ£ Aktion ausfÃ¼hren: MÃ¶gliche Aktionen (4 Tools) prÃ¼fen und ausfÃ¼hren. Each of the â€œtoolsâ€ in the system prompt correspond to a function in the code:
    # !!! Das LLM entscheidet, welches "Tool" (Werkzeug/Funktion) der Agent verwenden soll.
    # !!! MÃ¶gl. Tools: "list_files", "read_file", "error", "terminate"
    # !!! action["tool_name"] == "list_files": prÃ¼ft in jeder Iteration, welches Tool das Modell ausgewÃ¤hlt hat.

    # Wenn das Modell "list_files" auswÃ¤hlt â†’ alle Dateien im aktuellen Verzeichnis auflisten.
    if action["tool_name"] == "list_files": # "list_files" ist der Name des Tools 1
        result = {"result": list_files()} # Aufruf der Funktion (list_files()) zum Auflisten der Dateien

    # Wenn "read_file" â†’ Dateiinhalt lesen, Dateiname wird aus den Argumenten geholt.
    elif action["tool_name"] == "read_file": # "read_file" ist der Name des Tools 2
        result = {"result": read_file(action["args"]["file_name"])}

    # Wenn ein Fehler erkannt wurde â†’ Fehlermeldung zurÃ¼ckgeben.
    elif action["tool_name"] == "error": # "error" ist der Name des Tools 3
        result = {"error": action["args"]["message"]}

    # Wenn das Modell signalisiert, dass der Agent seine Arbeit beenden soll â†’ Schleife abbrechen.
    elif action["tool_name"] == "terminate": # "terminate" ist der Name des Tools 4
        print(action["args"]["message"])  # Nachricht anzeigen (z. B. "Task completed.")
        break

    # Wenn der Aktionsname unbekannt ist â†’ Fehler melden.
    else:
        result = {"error": "Unknown action: " + action["tool_name"]}

    # Ergebnis der ausgefÃ¼hrten Aktion anzeigen (zur Kontrolle oder Debugging)
    print(f"Action result: {result}")

    # 5ï¸âƒ£ Ergebnis in Zeichenfolge konvertieren: GedÃ¤chtnis (memory) aktualisieren:
    # Der Agent merkt sich, was er gesagt hat (assistant)
    # und was als Ergebnis (user input) zurÃ¼ckkam.
    # So kann das Modell spÃ¤ter darauf Bezug nehmen.
    memory.extend([
        {"role": "assistant", "content": response},
        {"role": "user", "content": json.dumps(result)}  # Ergebnis als JSON-Text speichern
    ])

    # 6ï¸âƒ£ Schleife fortsetzen: PrÃ¼fen, ob das Modell das Ende signalisiert hat
    # (z. B. Tool "terminate" wurde aufgerufen)
    if action["tool_name"] == "terminate":
        break

    # 7ï¸âƒ£ ZÃ¤hler erhÃ¶hen, um Endlosschleifen zu vermeiden 
    iterations += 1